{
 "metadata": {
  "name": "",
  "signature": "sha256:6d5f3784266469135dcb61a55bdec43ae004c8930351bd549a1b1e3150bdacbb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import sys\n",
      "import nltk\n",
      "import math\n",
      "\n",
      "#this function takes the words from the training data and returns a python list of all of the words that occur more than 5 times\n",
      "#wbrown is a python list where every element is a python list of the words of a particular sentence\n",
      "def calc_known(wbrown):\n",
      "    knownwords = []\n",
      "    dic={}\n",
      "    for l in wbrown:\n",
      "        for w in l:\n",
      "            if w in dic:\n",
      "                dic[w] += 1\n",
      "            else:\n",
      "                dic[w]=1\n",
      "            if dic[w]==6:\n",
      "                knownwords.append(w)\n",
      "    return knownwords\n",
      "\n",
      "#this function takes a set of sentences and a set of words that should not be marked '_RARE_'\n",
      "#brown is a python list where every element is a python list of the words of a particular sentence\n",
      "#and outputs a version of the set of sentences with rare words marked '_RARE_'\n",
      "def replace_rare(brown, knownwords):\n",
      "    rare = []\n",
      "    for l in brown:\n",
      "        temp=[]\n",
      "        for w in l:\n",
      "            if w in knownwords:\n",
      "                temp.append(w)\n",
      "            else:\n",
      "                temp.append(\"_RARE_\")\n",
      "        rare.append(temp) \n",
      "    return rare\n",
      "\n",
      "#this function takes the ouput from replace_rare and outputs it\n",
      "def q3_output(rare):\n",
      "    outfile = open(\"B3.txt\", 'w')\n",
      "\n",
      "    for sentence in rare:\n",
      "        outfile.write(' '.join(sentence[2:-1]) + '\\n')\n",
      "    outfile.close()\n",
      "\n",
      "#this function takes tags from the training data and calculates trigram probabilities\n",
      "#tbrown (the list of tags) should be a python list where every element is a python list of the tags of a particular sentence\n",
      "#it returns a python dictionary where the keys are tuples that represent the trigram, and the values are the log probability of that trigram\n",
      "def calc_trigrams(tbrown):\n",
      "    qvalues = {}\n",
      "    c={}\n",
      "    for l in tbrown:\n",
      "        for i in range(2, len(l)):\n",
      "            key=tuple((l[i-2], l[i-1], l[i],))\n",
      "            if key in qvalues:\n",
      "                qvalues[key] +=1\n",
      "            else:\n",
      "                qvalues[key] = 1\n",
      "                \n",
      "            key=tuple((l[i-1], l[i],))\n",
      "            if key in c:\n",
      "                c[key] +=1\n",
      "            else:\n",
      "                c[key] = 1\n",
      "    c[('*','*')]=len(tbrown)\n",
      "    for key in qvalues:\n",
      "        qvalues[key] = math.log(1.0*qvalues[key]/c[key[:-1]], 2)\n",
      "    \n",
      "    return qvalues\n",
      "\n",
      "#this function takes output from calc_trigrams() and outputs it in the proper format\n",
      "def q2_output(qvalues):\n",
      "    #output \n",
      "    outfile = open(\"B2.txt\", \"w\")\n",
      "    for trigram in qvalues:\n",
      "        output = \" \".join(['TRIGRAM', trigram[0], trigram[1], trigram[2], str(qvalues[trigram])])\n",
      "        outfile.write(output + '\\n')\n",
      "    outfile.close()\n",
      "\n",
      "#this function calculates emission probabilities and creates a list of possible tags\n",
      "#the first return value is a python dictionary where each key is a tuple in which the first element is a word \n",
      "#and the second is a tag and the value is the log probability of that word/tag pair\n",
      "#and the second return value is a list of possible tags for this data set\n",
      "#wbrown is a python list where each element is a python list of the words of a particular sentence\n",
      "#tbrown is a python list where each element is a python list of the tags of a particular sentence\n",
      "def calc_emission(wbrown, tbrown):\n",
      "    evalues = {}\n",
      "    taglist = []\n",
      "    count = {}\n",
      "    \n",
      "    for i in range(0, len(wbrown)):\n",
      "        for w in range(0, len(wbrown[i])):\n",
      "            t = tuple( (wbrown[i][w], tbrown[i][w]) )\n",
      "            if t in evalues:\n",
      "                evalues[t] += 1\n",
      "            else:\n",
      "                evalues[t] = 1\n",
      "            \n",
      "            if t[1] in count:\n",
      "                count[t[1]] += 1\n",
      "            else:\n",
      "                    count[t[1]] = 1\n",
      "                    taglist.append(t[1])\n",
      "    for key in evalues:\n",
      "        evalues[key] = math.log( 1.0*evalues[key]/count[key[1]], 2)\n",
      "    return evalues, taglist\n",
      "\n",
      "#this function takes the output from calc_emissions() and outputs it\n",
      "def q4_output(evalues):\n",
      "    #output\n",
      "    outfile = open(\"B4.txt\", \"w\")\n",
      "    for item in evalues:\n",
      "        output = \" \".join([item[0], item[1], str(evalues[item])])\n",
      "        outfile.write(output + '\\n')\n",
      "    outfile.close()\n",
      "\n",
      "\n",
      "#this function takes data to tag (brown), possible tags (taglist), a list of known words (knownwords), \n",
      "#trigram probabilities (qvalues) and emission probabilities (evalues) and outputs a list where every element is a string of a \n",
      "#sentence tagged in the WORD/TAG format \n",
      "#brown is a list where every element is a list of words\n",
      "#taglist is from the return of calc_emissions()\n",
      "#knownwords is from the the return of calc_knownwords()\n",
      "#qvalues is from the return of calc_trigrams\n",
      "#evalues is from the return of calc_emissions() \n",
      "#tagged is a list of tagged sentences in the format \"WORD/TAG\". Each sentence is a string, not a list of tokens.\n",
      "def viterbi(brown, taglist, knownwords, qvalues, evalues):\n",
      "    tagged = []\n",
      "    n=len(taglist)\n",
      "    \n",
      "    brown_rare = replace_rare(brown, knownwords)\n",
      "    \n",
      "    for line0, line in zip(brown, brown_rare):\n",
      "        \n",
      "        track=np.zeros( (len(line), n, n), dtype=int)\n",
      "        b=-1000*np.ones((n,n))\n",
      "        #b=np.zeros((n,n))\n",
      "        b[0,0]=0\n",
      "        for i in range(2, len(line)):            \n",
      "            temp=np.zeros((n,n))\n",
      "            for j in range(0, n):                \n",
      "                o=(line[i], taglist[j])\n",
      "                \n",
      "                start=-1000\n",
      "                if o in evalues:\n",
      "                    start = evalues[o]\n",
      "                else:\n",
      "                    temp[j,:]=-1000*np.ones(n)\n",
      "                    continue\n",
      "                \n",
      "                for k in range(0, n):\n",
      "                    m=-1000                    \n",
      "                    for l in range(0,n):\n",
      "                        p=b[k,l]\n",
      "                        t= (taglist[l], taglist[k], taglist[j])\n",
      "                        if t in qvalues:\n",
      "                            p += qvalues[t]\n",
      "                        else:\n",
      "                            p += -1000\n",
      "                        \n",
      "                        p+=start\n",
      "                        \n",
      "                        if p>m:\n",
      "                            m=p\n",
      "                            track[i, j, k] = l\n",
      "                    temp[j, k]=m\n",
      "            b=temp\n",
      "        # get seq\n",
      "        m=-1000\n",
      "        i=0\n",
      "        j=0\n",
      "        for k in xrange(n):\n",
      "            for l in xrange(n):\n",
      "                if b[k, l] > m:\n",
      "                    i=k\n",
      "                    j=l\n",
      "                    m=b[k, l]\n",
      "        w=len(line)-1\n",
      "        tags = np.zeros(len(line), dtype=int)\n",
      "        while w>=2:\n",
      "            if w<len(line)-1:\n",
      "                tags[w] = i\n",
      "            temp=track[w, i, j]\n",
      "            i=j\n",
      "            j=temp\n",
      "            w -= 1\n",
      "        newline=\"\"\n",
      "        for i in range(2, len(line)-1):\n",
      "            if i>2:\n",
      "                newline += \" \"\n",
      "            newline += line0[i]+\"/\"+taglist[tags[i]]\n",
      "        tagged.append(newline+\"\\n\")\n",
      "        \n",
      "\n",
      "            \n",
      "    return tagged\n",
      "\n",
      "#this function takes the output of viterbi() and outputs it\n",
      "def q5_output(tagged):\n",
      "    outfile = open('B5.txt', 'w')\n",
      "    for sentence in tagged:\n",
      "        outfile.write(sentence)\n",
      "    outfile.close()\n",
      "\n",
      "#this function uses nltk to create the taggers described in question 6\n",
      "#brown is the data to be tagged\n",
      "#tagged is a list of tagged sentences. Each sentence is in the WORD/TAG format and is a string rather than a list of tokens.\n",
      "def nltk_tagger(brown):\n",
      "    training = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
      "    default_tagger = nltk.DefaultTagger('NOUN')\n",
      "    bigram_tagger = nltk.BigramTagger(training, backoff=default_tagger)\n",
      "    trigram_tagger = nltk.TrigramTagger(training, backoff=bigram_tagger)\n",
      "    \n",
      "    tagged = []\n",
      "    for line in brown:\n",
      "        tags=trigram_tagger.tag(line)\n",
      "        s=[]\n",
      "        for i in range(2, len(line)-1):\n",
      "            s.append(tags[i][0]+\"/\"+tags[i][1])\n",
      "        tagged.append(s)\n",
      "    return tagged\n",
      "\n",
      "def q6_output(tagged):\n",
      "    outfile = open('B6.txt', 'w')\n",
      "    for sentence in tagged:\n",
      "        output = ' '.join(sentence) + '\\n'\n",
      "        outfile.write(output)\n",
      "    outfile.close()\n",
      "\n",
      "#a function that returns two lists, one of the brown data (words only) and another of the brown data (tags only) \n",
      "def split_wordtags(brown_train):\n",
      "    \n",
      "    def split_dash(word):\n",
      "        i=len(word)\n",
      "        while word[i-1]!='/' and i>0:\n",
      "            i=i-1\n",
      "        return word[:(i-1)], word[i:]\n",
      "    \n",
      "    wbrown = []\n",
      "    tbrown = []\n",
      "    for l in brown_train:\n",
      "        wl=[]\n",
      "        tl=[]\n",
      "        tokens = l.split() #nltk.word_tokenize(l)\n",
      "        wl += [\"*\",  \"*\"]\n",
      "        tl += [\"*\",  \"*\"]\n",
      "        for e in tokens:\n",
      "            s=split_dash(e)\n",
      "            wl.append(s[0])\n",
      "            tl.append(s[1])\n",
      "        wl.append(\"STOP\")\n",
      "        tl.append(\"STOP\")\n",
      "        wbrown+=[wl]\n",
      "        tbrown+=[tl]\n",
      "    return wbrown, tbrown\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(93.7008827776-92.9657787246)/93.7008827776\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "0.007845220143173865"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #open Brown training data\n",
      "    infile = open(\"Brown_tagged_train.txt\", \"r\")\n",
      "    brown_train = infile.readlines()\n",
      "    infile.close()\n",
      "    #brown_train=brown_train[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #split words and tags, and add start and stop symbols (question 1)\n",
      "    wbrown, tbrown = split_wordtags(brown_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "           \n",
      "    #calculate trigram probabilities (question 2)\n",
      "qvalues = calc_trigrams(tbrown)\n",
      "    \n",
      "    #question 2 output\n",
      "q2_output(qvalues)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #calculate list of words with count > 5 (question 3)\n",
      "    knownwords = calc_known(wbrown)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #get a version of wbrown with rare words replace with '_RARE_' (question 3)\n",
      "    wbrown_rare = replace_rare(wbrown, knownwords)\n",
      "\n",
      "    #question 3 output\n",
      "    q3_output(wbrown_rare)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #calculate emission probabilities (question 4)\n",
      "    evalues, taglist = calc_emission(wbrown_rare, tbrown)\n",
      "\n",
      "    #question 4 output\n",
      "    q4_output(evalues)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #delete unneceessary data\n",
      "    #del brown_train\n",
      "    #del wbrown\n",
      "    #del tbrown\n",
      "    #del wbrown_rare\n",
      "\n",
      "    #open Brown development data (question 5)\n",
      "    infile = open(\"Brown_dev.txt\", \"r\")\n",
      "    brown_dev = infile.readlines()#[:2]\n",
      "    infile.close()\n",
      "    \n",
      "    # FORMAT DATA!!!\n",
      "    temp=[]\n",
      "    for l in brown_dev:\n",
      "        temp.append( [\"*\",\"*\"]+l.split()+[\"STOP\"] )\n",
      "    brown_dev = temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #replace rare words in brown_dev (question 5)\n",
      "    t=time.time()\n",
      "\n",
      "    #do viterbi on brown_dev (question 5)\n",
      "    viterbi_tagged = viterbi(brown_dev, taglist, knownwords, qvalues, evalues)\n",
      "    print 100.0*(time.time()-t)/60\n",
      "    #question 5 output\n",
      "    q5_output(viterbi_tagged)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "388.377323548\n"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[[(u'The', u'DET'),\n",
        "  (u'Fulton', u'NOUN'),\n",
        "  (u'County', u'NOUN'),\n",
        "  (u'Grand', u'ADJ'),\n",
        "  (u'Jury', u'NOUN'),\n",
        "  (u'said', u'VERB'),\n",
        "  (u'Friday', u'NOUN'),\n",
        "  (u'an', u'DET'),\n",
        "  (u'investigation', u'NOUN'),\n",
        "  (u'of', u'ADP'),\n",
        "  (u\"Atlanta's\", u'NOUN'),\n",
        "  (u'recent', u'ADJ'),\n",
        "  (u'primary', u'NOUN'),\n",
        "  (u'election', u'NOUN'),\n",
        "  (u'produced', u'VERB'),\n",
        "  (u'``', u'.'),\n",
        "  (u'no', u'DET'),\n",
        "  (u'evidence', u'NOUN'),\n",
        "  (u\"''\", u'.'),\n",
        "  (u'that', u'ADP'),\n",
        "  (u'any', u'DET'),\n",
        "  (u'irregularities', u'NOUN'),\n",
        "  (u'took', u'VERB'),\n",
        "  (u'place', u'NOUN'),\n",
        "  (u'.', u'.')],\n",
        " [(u'The', u'DET'),\n",
        "  (u'jury', u'NOUN'),\n",
        "  (u'further', u'ADV'),\n",
        "  (u'said', u'VERB'),\n",
        "  (u'in', u'ADP'),\n",
        "  (u'term-end', u'NOUN'),\n",
        "  (u'presentments', u'NOUN'),\n",
        "  (u'that', u'ADP'),\n",
        "  (u'the', u'DET'),\n",
        "  (u'City', u'NOUN'),\n",
        "  (u'Executive', u'ADJ'),\n",
        "  (u'Committee', u'NOUN'),\n",
        "  (u',', u'.'),\n",
        "  (u'which', u'DET'),\n",
        "  (u'had', u'VERB'),\n",
        "  (u'over-all', u'ADJ'),\n",
        "  (u'charge', u'NOUN'),\n",
        "  (u'of', u'ADP'),\n",
        "  (u'the', u'DET'),\n",
        "  (u'election', u'NOUN'),\n",
        "  (u',', u'.'),\n",
        "  (u'``', u'.'),\n",
        "  (u'deserves', u'VERB'),\n",
        "  (u'the', u'DET'),\n",
        "  (u'praise', u'NOUN'),\n",
        "  (u'and', u'CONJ'),\n",
        "  (u'thanks', u'NOUN'),\n",
        "  (u'of', u'ADP'),\n",
        "  (u'the', u'DET'),\n",
        "  (u'City', u'NOUN'),\n",
        "  (u'of', u'ADP'),\n",
        "  (u'Atlanta', u'NOUN'),\n",
        "  (u\"''\", u'.'),\n",
        "  (u'for', u'ADP'),\n",
        "  (u'the', u'DET'),\n",
        "  (u'manner', u'NOUN'),\n",
        "  (u'in', u'ADP'),\n",
        "  (u'which', u'DET'),\n",
        "  (u'the', u'DET'),\n",
        "  (u'election', u'NOUN'),\n",
        "  (u'was', u'VERB'),\n",
        "  (u'conducted', u'VERB'),\n",
        "  (u'.', u'.')],\n",
        " [(u'The', u'DET'),\n",
        "  (u'September-October', u'NOUN'),\n",
        "  (u'term', u'NOUN'),\n",
        "  (u'jury', u'NOUN'),\n",
        "  (u'had', u'VERB'),\n",
        "  (u'been', u'VERB'),\n",
        "  (u'charged', u'VERB'),\n",
        "  (u'by', u'ADP'),\n",
        "  (u'Fulton', u'NOUN'),\n",
        "  (u'Superior', u'ADJ'),\n",
        "  (u'Court', u'NOUN'),\n",
        "  (u'Judge', u'NOUN'),\n",
        "  (u'Durwood', u'NOUN'),\n",
        "  (u'Pye', u'NOUN'),\n",
        "  (u'to', u'PRT'),\n",
        "  (u'investigate', u'VERB'),\n",
        "  (u'reports', u'NOUN'),\n",
        "  (u'of', u'ADP'),\n",
        "  (u'possible', u'ADJ'),\n",
        "  (u'``', u'.'),\n",
        "  (u'irregularities', u'NOUN'),\n",
        "  (u\"''\", u'.'),\n",
        "  (u'in', u'ADP'),\n",
        "  (u'the', u'DET'),\n",
        "  (u'hard-fought', u'ADJ'),\n",
        "  (u'primary', u'NOUN'),\n",
        "  (u'which', u'DET'),\n",
        "  (u'was', u'VERB'),\n",
        "  (u'won', u'VERB'),\n",
        "  (u'by', u'ADP'),\n",
        "  (u'Mayor-nominate', u'NOUN'),\n",
        "  (u'Ivan', u'NOUN'),\n",
        "  (u'Allen', u'NOUN'),\n",
        "  (u'Jr.', u'NOUN'),\n",
        "  (u'.', u'.')]]"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'He/PRON had/VERB obtained/VERB and/CONJ provisioned/VERB a/DET veteran/NOUN ship/NOUN called/VERB the/DET Discovery/NOUN and/CONJ had/VERB recruited/VERB a/DET crew/NOUN of/ADP twenty-one/NUM ,/. the/DET largest/ADJ he/PRON had/VERB ever/ADV commanded/VERB ./.', u'The/DET purpose/NOUN of/ADP this/DET fourth/ADJ voyage/NOUN was/VERB clear/ADJ ./.', u'A/NOUN century/NOUN of/ADP exploration/NOUN had/VERB established/VERB that/ADP a/DET great/ADJ land/NOUN mass/NOUN ,/. North/ADJ and/CONJ South/ADJ America/NOUN ,/. lay/VERB between/ADP Europe/NOUN and/CONJ the/DET Indies/NOUN ./.', u'One/NUM by/ADP one/NUM ,/. the/DET openings/NOUN in/ADP the/DET coast/NOUN that/ADP promised/NOUN a/DET passage/NOUN through/ADP had/VERB been/VERB explored/VERB and/CONJ discarded/VERB ./.', u\"In/ADP fact/NOUN ,/. Hudson's/NOUN sail/NOUN up/PRT the/DET Great/ADJ North/ADJ River/NOUN had/VERB disposed/VERB of/ADP one/NUM of/ADP the/DET last/ADJ hopes/NOUN ./.\", u'But/CONJ there/PRT remained/VERB one/NUM mysterious/ADJ ,/. unexplored/ADJ gap/NOUN ,/. far/ADV to/PRT the/DET north/NOUN ./.', u\"Nearly/NOUN twenty-five/NOUN years/NOUN before/ADP ,/. Captain/NOUN John/NOUN Davis/NOUN had/VERB noted/VERB ,/. as/ADP he/PRON sailed/VERB near/ADP the/DET Arctic/ADJ Circle/NOUN ,/. ``/. a/DET very/ADV great/ADJ gulf/NOUN ,/. the/DET water/NOUN whirling/VERB and/CONJ roaring/VERB ,/. as/ADP it/PRON were/VERB the/DET meeting/NOUN of/ADP tides/NOUN ''/. ./.\", u\"He/PRON named/VERB this/DET opening/NOUN ,/. between/ADP Baffin/NOUN Island/NOUN and/CONJ Labrador/NOUN ,/. the/DET ``/. Furious/ADJ Overfall/NOUN ''/. ./.\", u'(/. Later/ADV ,/. it/PRON was/VERB to/PRT be/VERB called/VERB Hudson/NOUN Strait/NOUN ./.', u')/. In/ADP 1602/NUM ,/. George/NOUN Waymouth/NOUN ,/. in/ADP the/DET same/ADJ little/ADJ Discovery/NOUN that/PRON Hudson/NOUN now/ADV commanded/VERB ,/. had/VERB sailed/VERB 300/NUM miles/NOUN up/ADP the/DET strait/NOUN before/ADP his/DET frightened/VERB men/NOUN turned/VERB the/DET ship/NOUN back/ADV ./.']\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #do nltk tagging here\n",
      "    from nltk.corpus import brown\n",
      "    training = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
      "    nltk_tagged = nltk_tagger(brown_dev[:10])\n",
      "    \n",
      "    #question 6 output\n",
      "    q6_output(nltk_tagged)\n",
      "#if __name__ == \"__main__\": main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk_tagged"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "[u'He/PRON had/VERB obtained/VERB and/CONJ provisioned/VERB a/DET veteran/NOUN ship/NOUN called/VERB the/DET Discovery/NOUN and/CONJ had/VERB recruited/VERB a/DET crew/NOUN of/ADP twenty-one/NUM ,/. the/DET largest/ADJ he/PRON had/VERB ever/ADV commanded/VERB ./.\\n',\n",
        " u'The/DET purpose/NOUN of/ADP this/DET fourth/ADJ voyage/NOUN was/VERB clear/ADJ ./.\\n',\n",
        " u'A/NOUN century/NOUN of/ADP exploration/NOUN had/VERB established/VERB that/ADP a/DET great/ADJ land/NOUN mass/NOUN ,/. North/ADJ and/CONJ South/ADJ America/NOUN ,/. lay/VERB between/ADP Europe/NOUN and/CONJ the/DET Indies/NOUN ./.\\n',\n",
        " u'One/NUM by/ADP one/NUM ,/. the/DET openings/NOUN in/ADP the/DET coast/NOUN that/ADP promised/NOUN a/DET passage/NOUN through/ADP had/VERB been/VERB explored/VERB and/CONJ discarded/VERB ./.\\n',\n",
        " u\"In/ADP fact/NOUN ,/. Hudson's/NOUN sail/NOUN up/PRT the/DET Great/ADJ North/ADJ River/NOUN had/VERB disposed/VERB of/ADP one/NUM of/ADP the/DET last/ADJ hopes/NOUN ./.\\n\",\n",
        " u'But/CONJ there/PRT remained/VERB one/NUM mysterious/ADJ ,/. unexplored/ADJ gap/NOUN ,/. far/ADV to/PRT the/DET north/NOUN ./.\\n',\n",
        " u\"Nearly/NOUN twenty-five/NOUN years/NOUN before/ADP ,/. Captain/NOUN John/NOUN Davis/NOUN had/VERB noted/VERB ,/. as/ADP he/PRON sailed/VERB near/ADP the/DET Arctic/ADJ Circle/NOUN ,/. ``/. a/DET very/ADV great/ADJ gulf/NOUN ,/. the/DET water/NOUN whirling/VERB and/CONJ roaring/VERB ,/. as/ADP it/PRON were/VERB the/DET meeting/NOUN of/ADP tides/NOUN ''/. ./.\\n\",\n",
        " u\"He/PRON named/VERB this/DET opening/NOUN ,/. between/ADP Baffin/NOUN Island/NOUN and/CONJ Labrador/NOUN ,/. the/DET ``/. Furious/ADJ Overfall/NOUN ''/. ./.\\n\",\n",
        " u'(/. Later/ADV ,/. it/PRON was/VERB to/PRT be/VERB called/VERB Hudson/NOUN Strait/NOUN ./.\\n',\n",
        " u')/. In/ADP 1602/NUM ,/. George/NOUN Waymouth/NOUN ,/. in/ADP the/DET same/ADJ little/ADJ Discovery/NOUN that/PRON Hudson/NOUN now/ADV commanded/VERB ,/. had/VERB sailed/VERB 300/NUM miles/NOUN up/ADP the/DET strait/NOUN before/ADP his/DET frightened/VERB men/NOUN turned/VERB the/DET ship/NOUN back/ADV ./.\\n']"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}